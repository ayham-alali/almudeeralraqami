"""
Al-Mudeer - LangGraph InboxCRM Agent
Implements: Ingest -> Classify -> Extract -> Draft pipeline
Optimized for low bandwidth with text-only responses
"""

import json
import re
from typing import TypedDict, Literal, Optional, Dict, Any
from dataclasses import dataclass
import httpx
import os

# LangGraph imports
from langgraph.graph import StateGraph, END

# Note: LLM configuration is centralized in services/llm_provider.py
# This file uses llm_generate() which handles OpenAI/Gemini failover

# Base system prompt for Arabic business context
BASE_SYSTEM_PROMPT = """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ÙƒØªØ¨ÙŠ Ø°ÙƒÙŠ Ù„Ù„Ø´Ø±ÙƒØ§Øª ÙÙŠ Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ. ØªØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…Ù‡Ù†ÙŠ ÙˆÙ…Ù‡Ø°Ø¨.
ØªÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø¬ÙŠØ¯Ø§Ù‹ (Ø§Ù„Ø¹Ù…Ù„Ø©ØŒ Ø§Ù„Ø¹Ø§Ø¯Ø§ØªØŒ Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ØªØ®Ø§Ø·Ø¨).
Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„ÙˆØ§Ø±Ø¯Ø© ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© ÙˆØµÙŠØ§ØºØ© Ø±Ø¯ÙˆØ¯ Ù…Ù†Ø§Ø³Ø¨Ø©.
ÙƒÙ† Ù…ÙˆØ¬Ø²Ø§Ù‹ ÙˆÙ…Ø¨Ø§Ø´Ø±Ø§Ù‹ ÙÙŠ Ø±Ø¯ÙˆØ¯Ùƒ Ù„ØªÙˆÙÙŠØ± Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."""


def build_system_prompt(preferences: Optional[Dict[str, Any]] = None) -> str:
    """
    Build a system prompt customized by workspace preferences.

    preferences comes from user_preferences table and may include:
    - tone: formal | friendly | custom
    - custom_tone_guidelines
    - business_name, industry, products_services
    - preferred_languages, reply_length, formality_level
    """
    if not preferences:
        return BASE_SYSTEM_PROMPT

    tone = (preferences.get("tone") or "formal").lower()
    custom_guidelines = (preferences.get("custom_tone_guidelines") or "").strip()

    # Tone description
    if tone == "friendly":
        tone_desc = "Ø§Ø³ØªØ®Ø¯Ù… Ù†Ø¨Ø±Ø© ÙˆØ¯ÙŠØ© ÙˆÙ‚Ø±ÙŠØ¨Ø© Ù„ÙƒÙ† Ù…Ø¹ Ø§Ø­ØªØ±Ø§Ù… Ù…Ù‡Ù†ÙŠØŒ ÙˆØªØ¬Ù†Ù‘Ø¨ Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø§Ù„Ø«Ù‚ÙŠÙ„Ø©."
    elif tone == "custom" and custom_guidelines:
        tone_desc = custom_guidelines
    else:
        # formal or unknown
        tone_desc = "Ø§Ø³ØªØ®Ø¯Ù… Ù†Ø¨Ø±Ø© Ø±Ø³Ù…ÙŠØ© Ø¨Ø³ÙŠØ·Ø© ÙˆÙˆØ§Ø¶Ø­Ø© Ø¨Ø¯ÙˆÙ† Ù…Ø¨Ø§Ù„ØºØ© ÙÙŠ Ø§Ù„Ù…Ø¬Ø§Ù…Ù„Ø§Øª."

    business_name = preferences.get("business_name") or "Ø§Ù„Ø´Ø±ÙƒØ©"
    industry = preferences.get("industry") or ""
    products = preferences.get("products_services") or ""

    business_context_parts = [f"ØªØªØ­Ø¯Ø« Ø¨Ø§Ø³Ù… {business_name}."]
    if industry:
        business_context_parts.append(f"Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ: {industry}.")
    if products:
        business_context_parts.append(f"Ø§Ù„Ø®Ø¯Ù…Ø§Øª / Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {products}.")

    reply_length = (preferences.get("reply_length") or "").lower()
    if reply_length == "short":
        length_hint = "Ø§Ø­Ø±Øµ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø±Ø¯ Ù‚ØµÙŠØ±Ø§Ù‹ Ù‚Ø¯Ø± Ø§Ù„Ø¥Ù…ÙƒØ§Ù† (Ù…Ù† 2 Ø¥Ù„Ù‰ 3 Ø£Ø³Ø·Ø± ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹)."
    elif reply_length == "long":
        length_hint = "ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø±Ø¯ Ù…ÙØµÙ„Ø§Ù‹ Ø£ÙƒØ«Ø± Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©ØŒ Ù…Ø¹ Ø§Ù„Ù…Ø­Ø§ÙØ¸Ø© Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¶ÙˆØ­."
    else:
        length_hint = "Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø·ÙˆÙ„ Ø±Ø¯ Ù…ØªÙˆØ³Ø· ÙˆÙˆØ§Ø¶Ø­ (Ø­ÙˆØ§Ù„ÙŠ 3 Ø¥Ù„Ù‰ 6 Ø£Ø³Ø·Ø±)."

    return (
        BASE_SYSTEM_PROMPT
        + "\n\n"
        + "Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¹Ù…Ù„:\n"
        + " ".join(business_context_parts)
        + "\n\nØ£Ø³Ù„ÙˆØ¨ Ø§Ù„ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:\n"
        + tone_desc
        + "\n"
        + length_hint
    )


class AgentState(TypedDict):
    """State for the InboxCRM agent"""
    # Input
    raw_message: str
    message_type: str  # email, whatsapp, general
    
    # Classification
    intent: str  # Ø§Ø³ØªÙØ³Ø§Ø±, Ø·Ù„Ø¨ Ø®Ø¯Ù…Ø©, Ø´ÙƒÙˆÙ‰, Ù…ØªØ§Ø¨Ø¹Ø©, Ø¹Ø±Ø¶, Ø£Ø®Ø±Ù‰
    urgency: str  # Ø¹Ø§Ø¬Ù„, Ø¹Ø§Ø¯ÙŠ, Ù…Ù†Ø®ÙØ¶
    sentiment: str  # Ø¥ÙŠØ¬Ø§Ø¨ÙŠ, Ù…Ø­Ø§ÙŠØ¯, Ø³Ù„Ø¨ÙŠ
    language: Optional[str]
    dialect: Optional[str]
    
    # Extraction
    sender_name: Optional[str]
    sender_contact: Optional[str]
    key_points: list[str]
    action_items: list[str]
    extracted_entities: dict  # dates, amounts, product names, etc.
    
    # Output
    summary: str
    draft_response: str
    suggested_actions: list[str]
    
    # Metadata
    error: Optional[str]
    processing_step: str

    # Preferences / context
    preferences: Optional[Dict[str, Any]]
    # Recent conversation history (plain text)
    conversation_history: Optional[str]


async def call_llm(
    prompt: str,
    system: Optional[str] = None,
    json_mode: bool = False,
    max_tokens: int = 600,
) -> Optional[str]:
    """
    Call LLM using multi-provider service with automatic failover.

    Provider chain: OpenAI -> Google Gemini -> Rule-based fallback
    
    Features:
    - Automatic failover between providers
    - Response caching to reduce API calls
    - Circuit breaker for failing providers
    - Exponential backoff for rate limiting
    
    Returns None if all providers fail (caller should use rule-based logic).
    """
    try:
        from services.llm_provider import llm_generate
        
        effective_system = system or BASE_SYSTEM_PROMPT
        
        response = await llm_generate(
            prompt=prompt,
            system=effective_system,
            json_mode=json_mode,
            max_tokens=max_tokens,
            temperature=0.3
        )
        
        return response
    except Exception as e:
        # If LLM fails, return None to trigger rule-based fallback
        print(f"LLM service error: {e}")
        return None



def rule_based_classify(message: str) -> dict:
    """Rule-based classification fallback (works offline)"""
    message_lower = message.lower()
    
    # Intent detection
    intent = "Ø£Ø®Ø±Ù‰"
    if any(word in message for word in ["Ø³Ø¹Ø±", "ÙƒÙ…", "ØªÙƒÙ„ÙØ©", "Ø£Ø³Ø¹Ø§Ø±"]):
        intent = "Ø§Ø³ØªÙØ³Ø§Ø±"
    elif any(word in message for word in ["Ø£Ø±ÙŠØ¯", "Ø£Ø±ØºØ¨", "Ø·Ù„Ø¨", "Ø§Ø­ØªØ§Ø¬", "Ù†Ø±ÙŠØ¯"]):
        intent = "Ø·Ù„Ø¨ Ø®Ø¯Ù…Ø©"
    elif any(word in message for word in ["Ø´ÙƒÙˆÙ‰", "Ù…Ø´ÙƒÙ„Ø©", "Ù„Ù… ÙŠØ¹Ù…Ù„", "ØªØ£Ø®Ø±", "Ø³ÙŠØ¡"]):
        intent = "Ø´ÙƒÙˆÙ‰"
    elif any(word in message for word in ["Ù…ØªØ§Ø¨Ø¹Ø©", "Ø¨Ø®ØµÙˆØµ", "Ø§Ø³ØªÙƒÙ…Ø§Ù„", "ØªØ°ÙƒÙŠØ±"]):
        intent = "Ù…ØªØ§Ø¨Ø¹Ø©"
    elif any(word in message for word in ["Ø¹Ø±Ø¶", "Ø®ØµÙ…", "ØªØ®ÙÙŠØ¶", "ÙØ±ØµØ©"]):
        intent = "Ø¹Ø±Ø¶"
    
    # Urgency detection
    urgency = "Ø¹Ø§Ø¯ÙŠ"
    if any(word in message for word in ["Ø¹Ø§Ø¬Ù„", "ÙÙˆØ±ÙŠ", "Ø§Ù„ÙŠÙˆÙ…", "Ø§Ù„Ø¢Ù†", "Ø¶Ø±ÙˆØ±ÙŠ"]):
        urgency = "Ø¹Ø§Ø¬Ù„"
    elif any(word in message for word in ["Ù„Ø§Ø­Ù‚Ø§Ù‹", "Ø¹Ù†Ø¯Ù…Ø§", "Ù…ØªÙ‰ Ù…Ø§"]):
        urgency = "Ù…Ù†Ø®ÙØ¶"
    
    # Sentiment detection
    sentiment = "Ù…Ø­Ø§ÙŠØ¯"
    if any(word in message for word in ["Ø´ÙƒØ±Ø§Ù‹", "Ù…Ù…ØªØ§Ø²", "Ø±Ø§Ø¦Ø¹", "Ø³Ø¹ÙŠØ¯", "Ù…Ø³Ø±ÙˆØ±"]):
        sentiment = "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ"
    elif any(word in message for word in ["ØºØ§Ø¶Ø¨", "Ù…Ø­Ø¨Ø·", "Ø³ÙŠØ¡", "Ù…Ø³ØªØ§Ø¡", "Ù„Ù„Ø£Ø³Ù"]):
        sentiment = "Ø³Ù„Ø¨ÙŠ"
    
    return {"intent": intent, "urgency": urgency, "sentiment": sentiment}


def extract_entities(message: str) -> dict:
    """Extract entities using regex patterns"""
    entities = {}
    
    # Phone numbers (Syrian/Arabic format)
    phone_patterns = [
        r'(?:00963|\+963|0)?9\d{8}',  # Syrian mobile
        r'(?:00963|\+963|0)?11\d{7}',  # Damascus landline
        r'\d{3}[-.\s]?\d{3}[-.\s]?\d{4}',  # General format
    ]
    phones = []
    for pattern in phone_patterns:
        phones.extend(re.findall(pattern, message))
    if phones:
        entities["phones"] = list(set(phones))
    
    # Email
    emails = re.findall(r'[\w\.-]+@[\w\.-]+\.\w+', message)
    if emails:
        entities["emails"] = emails
    
    # Dates (Arabic format)
    dates = re.findall(r'\d{1,2}[/\-]\d{1,2}[/\-]\d{2,4}', message)
    if dates:
        entities["dates"] = dates
    
    # Money amounts
    amounts = re.findall(r'(\d+(?:,\d{3})*(?:\.\d+)?)\s*(?:Ù„\.Ø³|Ù„ÙŠØ±Ø©|Ø¯ÙˆÙ„Ø§Ø±|\$|USD)', message)
    if amounts:
        entities["amounts"] = amounts
    
    # Extract possible name (after Ø§Ù„Ø³ÙŠØ¯/Ø§Ù„Ø³ÙŠØ¯Ø©/Ø§Ù„Ø£Ø³ØªØ§Ø°)
    name_match = re.search(r'(?:Ø§Ù„Ø³ÙŠØ¯|Ø§Ù„Ø³ÙŠØ¯Ø©|Ø§Ù„Ø£Ø³ØªØ§Ø°|Ø§Ù„Ø£Ø³ØªØ§Ø°Ø©|Ø£Ø®ÙŠ|Ø£Ø®ØªÙŠ)\s+([\u0600-\u06FF\s]+)', message)
    if name_match:
        entities["mentioned_name"] = name_match.group(1).strip()
    
    return entities


def generate_rule_based_response(state: dict) -> str:
    """Generate a draft response based on intent"""
    intent = state.get("intent", "Ø£Ø®Ø±Ù‰")
    sender = state.get("sender_name", "Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„ÙƒØ±ÙŠÙ…")
    
    templates = {
        "Ø§Ø³ØªÙØ³Ø§Ø±": f"""Ø§Ù„Ø³ÙŠØ¯/Ø§Ù„Ø³ÙŠØ¯Ø© {sender} Ø§Ù„Ù…Ø­ØªØ±Ù…/Ø©ØŒ

Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙˆØ§ØµÙ„ÙƒÙ… Ù…Ø¹Ù†Ø§.

Ø¨Ø®ØµÙˆØµ Ø§Ø³ØªÙØ³Ø§Ø±ÙƒÙ…ØŒ Ù†ÙˆØ¯ Ø¥ÙØ§Ø¯ØªÙƒÙ… Ø¨Ø£Ù† [Ø£Ø¶Ù Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ù‡Ù†Ø§].

Ù†Ø±Ø­Ø¨ Ø¨Ø£ÙŠ Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©.

Ù…Ø¹ Ø£Ø·ÙŠØ¨ Ø§Ù„ØªØ­ÙŠØ§ØªØŒ
ÙØ±ÙŠÙ‚ Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡""",
        
        "Ø·Ù„Ø¨ Ø®Ø¯Ù…Ø©": f"""Ø§Ù„Ø³ÙŠØ¯/Ø§Ù„Ø³ÙŠØ¯Ø© {sender} Ø§Ù„Ù…Ø­ØªØ±Ù…/Ø©ØŒ

Ø´ÙƒØ±Ø§Ù‹ Ù„Ø«Ù‚ØªÙƒÙ… Ø¨Ø®Ø¯Ù…Ø§ØªÙ†Ø§.

ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø·Ù„Ø¨ÙƒÙ… Ø¨Ù†Ø¬Ø§Ø­ ÙˆØ³ÙŠØªÙ… Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ÙƒÙ… Ù‚Ø±ÙŠØ¨Ø§Ù‹ Ù„Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª.

Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø£Ùˆ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±ØŒ Ù†Ø­Ù† Ø¨Ø®Ø¯Ù…ØªÙƒÙ….

Ù…Ø¹ Ø£Ø·ÙŠØ¨ Ø§Ù„ØªØ­ÙŠØ§ØªØŒ
ÙØ±ÙŠÙ‚ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª""",
        
        "Ø´ÙƒÙˆÙ‰": f"""Ø§Ù„Ø³ÙŠØ¯/Ø§Ù„Ø³ÙŠØ¯Ø© {sender} Ø§Ù„Ù…Ø­ØªØ±Ù…/Ø©ØŒ

Ù†Ø¹ØªØ°Ø± Ø¹Ù† Ø£ÙŠ Ø¥Ø²Ø¹Ø§Ø¬ Ø³Ø¨Ø¨Ù†Ø§Ù‡ Ù„ÙƒÙ….

ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ù…Ù„Ø§Ø­Ø¸Ø§ØªÙƒÙ… ÙˆØ³ÙŠØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ø£Ù‚ØµÙ‰ Ø³Ø±Ø¹Ø©.
Ø³Ù†ØªÙˆØ§ØµÙ„ Ù…Ø¹ÙƒÙ… Ø®Ù„Ø§Ù„ [Ø­Ø¯Ø¯ Ø§Ù„Ù…Ø¯Ø©] Ù„Ø¥Ø·Ù„Ø§Ø¹ÙƒÙ… Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªØ¬Ø¯Ø§Øª.

Ù†Ù‚Ø¯Ø± ØµØ¨Ø±ÙƒÙ… ÙˆØªÙÙ‡Ù…ÙƒÙ….

Ù…Ø¹ Ø£Ø·ÙŠØ¨ Ø§Ù„ØªØ­ÙŠØ§ØªØŒ
ÙØ±ÙŠÙ‚ Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡""",
        
        "Ù…ØªØ§Ø¨Ø¹Ø©": f"""Ø§Ù„Ø³ÙŠØ¯/Ø§Ù„Ø³ÙŠØ¯Ø© {sender} Ø§Ù„Ù…Ø­ØªØ±Ù…/Ø©ØŒ

Ø´ÙƒØ±Ø§Ù‹ Ù„Ù…ØªØ§Ø¨Ø¹ØªÙƒÙ….

Ø¨Ø®ØµÙˆØµ Ù…ÙˆØ¶ÙˆØ¹ÙƒÙ…ØŒ Ù†ÙˆØ¯ Ø¥ÙØ§Ø¯ØªÙƒÙ… Ø¨Ø£Ù† [Ø£Ø¶Ù Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©].

Ø³Ù†Ø¨Ù‚ÙŠÙƒÙ… Ø¹Ù„Ù‰ Ø§Ø·Ù„Ø§Ø¹ Ø¨Ø£ÙŠ ØªØ­Ø¯ÙŠØ«Ø§Øª.

Ù…Ø¹ Ø£Ø·ÙŠØ¨ Ø§Ù„ØªØ­ÙŠØ§ØªØŒ
ÙØ±ÙŠÙ‚ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©""",
        
        "Ø¹Ø±Ø¶": f"""Ø§Ù„Ø³ÙŠØ¯/Ø§Ù„Ø³ÙŠØ¯Ø© {sender} Ø§Ù„Ù…Ø­ØªØ±Ù…/Ø©ØŒ

Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙˆØ§ØµÙ„ÙƒÙ… ÙˆØ¹Ø±Ø¶ÙƒÙ… Ø§Ù„ÙƒØ±ÙŠÙ….

Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù‚Ø¯Ù… ÙˆØ§Ù„Ø±Ø¯ Ø¹Ù„ÙŠÙƒÙ… ÙÙŠ Ø£Ù‚Ø±Ø¨ ÙˆÙ‚Øª.

Ù…Ø¹ Ø£Ø·ÙŠØ¨ Ø§Ù„ØªØ­ÙŠØ§ØªØŒ
ÙØ±ÙŠÙ‚ Ø§Ù„Ù…Ø´ØªØ±ÙŠØ§Øª""",
        
        "Ø£Ø®Ø±Ù‰": f"""Ø§Ù„Ø³ÙŠØ¯/Ø§Ù„Ø³ÙŠØ¯Ø© {sender} Ø§Ù„Ù…Ø­ØªØ±Ù…/Ø©ØŒ

Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙˆØ§ØµÙ„ÙƒÙ… Ù…Ø¹Ù†Ø§.

ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø±Ø³Ø§Ù„ØªÙƒÙ… ÙˆØ³Ù†Ù‚ÙˆÙ… Ø¨Ø§Ù„Ø±Ø¯ Ø¹Ù„ÙŠÙƒÙ… Ù‚Ø±ÙŠØ¨Ø§Ù‹.

Ù…Ø¹ Ø£Ø·ÙŠØ¨ Ø§Ù„ØªØ­ÙŠØ§ØªØŒ
ÙØ±ÙŠÙ‚ Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡"""
    }
    
    return templates.get(intent, templates["Ø£Ø®Ø±Ù‰"])


# ============ LangGraph Nodes ============

async def ingest_node(state: AgentState) -> AgentState:
    """Step 1: Ingest and clean the message"""
    state["processing_step"] = "Ø§Ø³ØªÙ„Ø§Ù…"
    
    # Clean the message
    raw = state["raw_message"].strip()
    
    # Detect message type if not specified
    if not state.get("message_type"):
        if "@" in raw and "subject" in raw.lower():
            state["message_type"] = "email"
        elif any(x in raw for x in ["ÙˆØ§ØªØ³Ø§Ø¨", "whatsapp", "ğŸ“±"]):
            state["message_type"] = "whatsapp"
        else:
            state["message_type"] = "general"
    
    return state


async def classify_node(state: AgentState) -> AgentState:
    """Step 2: Classify intent, urgency, and sentiment"""
    state["processing_step"] = "ØªØµÙ†ÙŠÙ"
    
    # Try LLM first â€“ structured JSON output in Arabic business context
    history_block = ""
    if state.get("conversation_history"):
        history_block = f"\nØ³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù…Ø¹ Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù…ÙŠÙ„ (Ù…Ù† Ø§Ù„Ø£Ø­Ø¯Ø« Ø¥Ù„Ù‰ Ø§Ù„Ø£Ù‚Ø¯Ù…):\n{state['conversation_history']}\n"

    prompt = f"""Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø®Ø¯Ù…Ø© Ø¹Ù…Ù„Ø§Ø¡ ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆÙ„ØºØ§Øª Ø£Ø®Ø±Ù‰.
Ø­Ù„Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆØ£Ø¹Ø·Ù†ÙŠ:
1. Ø§Ù„Ù†ÙŠØ© (intent): Ø§Ø³ØªÙØ³Ø§Ø±ØŒ Ø·Ù„Ø¨ Ø®Ø¯Ù…Ø©ØŒ Ø´ÙƒÙˆÙ‰ØŒ Ù…ØªØ§Ø¨Ø¹Ø©ØŒ Ø¹Ø±Ø¶ØŒ Ø£Ø®Ø±Ù‰
2. Ø§Ù„Ø£Ù‡Ù…ÙŠØ© (urgency): Ø¹Ø§Ø¬Ù„ØŒ Ø¹Ø§Ø¯ÙŠØŒ Ù…Ù†Ø®ÙØ¶
3. Ø§Ù„Ù…Ø´Ø§Ø¹Ø± (sentiment): Ø¥ÙŠØ¬Ø§Ø¨ÙŠØŒ Ù…Ø­Ø§ÙŠØ¯ØŒ Ø³Ù„Ø¨ÙŠ
4. Ø§Ù„Ù„ØºØ© (language): ar, en, fr, Ø£Ùˆ Ø±Ù…Ø² ISO Ø¥Ù† Ø£Ù…ÙƒÙ†
5. Ø§Ù„Ù„Ù‡Ø¬Ø© (dialect): Ø³ÙˆØ±ÙŠØŒ Ø³Ø¹ÙˆØ¯ÙŠØŒ Ù…ØµØ±ÙŠØŒ Ø®Ù„ÙŠØ¬ÙŠØŒ ÙØµØ­Ù‰ØŒ Ø£Ùˆ Other

Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø©ØŒ ÙˆØªØ¬Ù†Ø¨ Ø§Ù„Ø­ÙƒÙ… Ù…Ù† ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·.
{history_block}
Ø§Ù„Ù†Øµ Ø§Ù„Ø­Ø§Ù„ÙŠ:
{state['raw_message']}

Ø£Ø±Ø¬Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø· Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø´ÙƒÙ„:
{{"intent": "Ø§Ø³ØªÙØ³Ø§Ø±", "urgency": "Ø¹Ø§Ø¯ÙŠ", "sentiment": "Ù…Ø­Ø§ÙŠØ¯", "language": "ar", "dialect": "Ø´Ø§Ù…ÙŠ"}}"""

    llm_response = await call_llm(
        prompt,
        system=build_system_prompt(state.get("preferences")),
        json_mode=True,
    )
    
    if llm_response:
        try:
            classification = json.loads(llm_response)
            state["intent"] = classification.get("intent", "Ø£Ø®Ø±Ù‰")
            state["urgency"] = classification.get("urgency", "Ø¹Ø§Ø¯ÙŠ")
            state["sentiment"] = classification.get("sentiment", "Ù…Ø­Ø§ÙŠØ¯")
            state["language"] = classification.get("language") or "ar"
            state["dialect"] = classification.get("dialect")
            return state
        except json.JSONDecodeError:
            pass
    
    # Fallback to rule-based
    classification = rule_based_classify(state["raw_message"])
    state["intent"] = classification["intent"]
    state["urgency"] = classification["urgency"]
    state["sentiment"] = classification["sentiment"]
    
    return state


async def extract_node(state: AgentState) -> AgentState:
    """Step 3: Extract key information"""
    state["processing_step"] = "Ø§Ø³ØªØ®Ø±Ø§Ø¬"
    
    # Extract entities using regex (reliable, no LLM needed)
    entities = extract_entities(state["raw_message"])
    state["extracted_entities"] = entities
    
    # Set sender info from entities if found
    if entities.get("mentioned_name"):
        state["sender_name"] = entities["mentioned_name"]
    if entities.get("emails"):
        state["sender_contact"] = entities["emails"][0]
    elif entities.get("phones"):
        state["sender_contact"] = entities["phones"][0]
    
    # Try LLM for key points extraction
    history_block = ""
    if state.get("conversation_history"):
        history_block = f"\nØ³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù…Ø¹ Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù…ÙŠÙ„ (Ù…Ù† Ø§Ù„Ø£Ø­Ø¯Ø« Ø¥Ù„Ù‰ Ø§Ù„Ø£Ù‚Ø¯Ù…):\n{state['conversation_history']}\n"

    prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ÙŠØ¯Ø¹Ù… ÙØ±ÙŠÙ‚ Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡.
Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ø§Ø³ØªØ®Ø±Ø¬ Ø¨Ø§Ø®ØªØµØ§Ø±:
1. Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„ØªÙŠ ÙŠØ°ÙƒØ±Ù‡Ø§ Ø§Ù„Ø¹Ù…ÙŠÙ„ (3 Ù†Ù‚Ø§Ø· ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰).
2. Ø£Ù‡Ù… Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø£Ùˆ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªÙŠ ÙŠÙ†Ø¨ØºÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙØ±ÙŠÙ‚ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ù‡Ø§.

ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù„ØºØ© Ø¹Ø±Ø¨ÙŠØ© ÙØµØ­Ù‰ Ø¨Ø³ÙŠØ·Ø© ÙˆÙ…Ø¨Ø§Ø´Ø±Ø©.
{history_block}
Ù†Øµ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©:
{state['raw_message']}

Ø£Ø±Ø¬Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø· Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø´ÙƒÙ„:
{{"key_points": ["Ù†Ù‚Ø·Ø© Ù…Ø®ØªØµØ±Ø© 1", "Ù†Ù‚Ø·Ø© Ù…Ø®ØªØµØ±Ø© 2"], "action_items": ["Ø¥Ø¬Ø±Ø§Ø¡ ÙˆØ§Ø¶Ø­ 1"]}}"""

    llm_response = await call_llm(
        prompt,
        system=build_system_prompt(state.get("preferences")),
        json_mode=True,
    )
    
    if llm_response:
        try:
            extracted = json.loads(llm_response)
            state["key_points"] = extracted.get("key_points", [])
            state["action_items"] = extracted.get("action_items", [])
            return state
        except json.JSONDecodeError:
            pass
    
    # Fallback: Basic extraction
    sentences = state["raw_message"].split('.')
    state["key_points"] = [s.strip() for s in sentences[:3] if s.strip()]
    state["action_items"] = ["Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø·Ù„Ø¨", "Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù…ÙŠÙ„"]
    
    return state


async def draft_node(state: AgentState) -> AgentState:
    """Step 4: Draft a response"""
    state["processing_step"] = "ØµÙŠØ§ØºØ©"
    
    sender = state.get("sender_name", "Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„ÙƒØ±ÙŠÙ…")
    intent = state.get("intent", "Ø£Ø®Ø±Ù‰")
    key_points = state.get("key_points", [])
    
    # Try LLM for natural, personalized Arabic response
    history_block = ""
    if state.get("conversation_history"):
        history_block = f"\nØ³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù…Ø¹ Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù…ÙŠÙ„ (Ù…Ù† Ø§Ù„Ø£Ø­Ø¯Ø« Ø¥Ù„Ù‰ Ø§Ù„Ø£Ù‚Ø¯Ù…):\n{state['conversation_history']}\n"

    prompt = f"""Ø£Ù†Øª Ù…ÙˆØ¸Ù Ø®Ø¯Ù…Ø© Ø¹Ù…Ù„Ø§Ø¡ Ù…Ø­ØªØ±Ù ÙÙŠ Ø´Ø±ÙƒØ© Ø¹Ø±Ø¨ÙŠØ©.
Ø§ÙƒØªØ¨ Ø±Ø¯Ø§Ù‹ Ø¨Ø´Ø±ÙŠØ§Ù‹ Ø·Ø¨ÙŠØ¹ÙŠØ§Ù‹ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ù…Ø¨Ø³Ù‘Ø·Ø© (Ù„ÙŠØ³Øª Ø±Ø³Ù…ÙŠØ© Ø¬Ø¯Ø§Ù‹ ÙˆÙ„Ø§ Ø¹Ø§Ù…ÙŠØ©).

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ù† Ø§Ù„Ø±Ø¯:
- Ø£Ù† ÙŠÙƒÙˆÙ† Ù…ÙˆØ¬Ù‡Ø§Ù‹ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ù…ÙŠÙ„ ({sender}) Ø¥Ù† Ø£Ù…ÙƒÙ† Ø°ÙƒØ± Ø§Ù„Ø§Ø³Ù….
- Ø£Ù† ÙŠÙˆØ¶Ø­ Ø£Ù†Ùƒ Ù‚Ø±Ø£Øª Ø§Ù„Ø±Ø³Ø§Ù„Ø© ÙˆÙÙ‡Ù…Øª Ù…Ø¶Ù…ÙˆÙ†Ù‡Ø§ (Ø¨Ø§Ø®ØªØµØ§Ø±).
- Ø£Ù† ÙŠÙ‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ùˆ Ø®Ø·ÙˆØ§Øª ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø­Ø¯Ø¯Ø©.
- Ø£Ù† ÙŠÙƒÙˆÙ† Ù…Ø´Ø¬Ø¹Ø§Ù‹ ÙˆÙ„Ø·ÙŠÙØ§Ù‹ØŒ Ø¨Ø¯ÙˆÙ† Ù…Ø¨Ø§Ù„ØºØ© ÙÙŠ Ø§Ù„Ù…Ø¬Ø§Ù…Ù„Ø§Øª Ø£Ùˆ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©.
- Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: Ù…Ù† 3 Ø¥Ù„Ù‰ 6 Ø£Ø³Ø·Ø± ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰.

Ù†ÙˆØ¹ Ø§Ù„Ø±Ø³Ø§Ù„Ø© (Ù†ÙŠØ© Ø§Ù„Ø¹Ù…ÙŠÙ„): {intent}
Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©: {', '.join(key_points) or 'Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ù‚Ø§Ø· ÙˆØ§Ø¶Ø­Ø©'}
{history_block}
Ù†Øµ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠØ©:
{state['raw_message']}

Ø§ÙƒØªØ¨ Ø§Ù„Ø±Ø¯ ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø´Ø±Ø­ Ø¥Ø¶Ø§ÙÙŠ Ø£Ùˆ ØªØ¹Ø¯Ø§Ø¯ Ù†Ù‚Ø·ÙŠ."""

    llm_response = await call_llm(
        prompt,
        system=build_system_prompt(state.get("preferences")),
        json_mode=False,
        max_tokens=400,
    )
    
    if llm_response and len(llm_response.strip()) > 40:
        state["draft_response"] = llm_response.strip()
    else:
        # Use template-based response
        state["draft_response"] = generate_rule_based_response(state)
    
    # Generate summary
    state["summary"] = f"Ø±Ø³Ø§Ù„Ø© {intent} Ù…Ù† {sender}. Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {state.get('sentiment', 'Ù…Ø­Ø§ÙŠØ¯')}. Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: {state.get('urgency', 'Ø¹Ø§Ø¯ÙŠ')}."
    
    # Suggested actions based on intent
    actions_map = {
        "Ø§Ø³ØªÙØ³Ø§Ø±": ["Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±", "Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©"],
        "Ø·Ù„Ø¨ Ø®Ø¯Ù…Ø©": ["Ø¥Ù†Ø´Ø§Ø¡ Ø·Ù„Ø¨ Ø¬Ø¯ÙŠØ¯", "ØªØ­Ø¯ÙŠØ¯ Ù…ÙˆØ¹Ø¯", "Ø¥Ø±Ø³Ø§Ù„ Ø¹Ø±Ø¶ Ø³Ø¹Ø±"],
        "Ø´ÙƒÙˆÙ‰": ["ØªØµØ¹ÙŠØ¯ Ù„Ù„Ù…Ø¯ÙŠØ±", "ÙØªØ­ ØªØ°ÙƒØ±Ø© Ø¯Ø¹Ù…", "Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¹Ù…ÙŠÙ„"],
        "Ù…ØªØ§Ø¨Ø¹Ø©": ["ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ù„Ø¨", "Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ±"],
        "Ø¹Ø±Ø¶": ["Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ø¹Ø±Ø¶", "ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ù…Ø´ØªØ±ÙŠØ§Øª"],
        "Ø£Ø®Ø±Ù‰": ["Ù…Ø±Ø§Ø¬Ø¹Ø© ÙŠØ¯ÙˆÙŠØ©", "ØªØµÙ†ÙŠÙ Ø§Ù„Ø±Ø³Ø§Ù„Ø©"]
    }
    state["suggested_actions"] = actions_map.get(intent, actions_map["Ø£Ø®Ø±Ù‰"])
    
    return state


# ============ Build the Graph ============

def create_inbox_agent():
    """Create the InboxCRM LangGraph agent"""
    
    # Create the graph
    workflow = StateGraph(AgentState)
    
    # Add nodes
    workflow.add_node("ingest", ingest_node)
    workflow.add_node("classify", classify_node)
    workflow.add_node("extract", extract_node)
    workflow.add_node("draft", draft_node)
    
    # Define edges (linear pipeline)
    workflow.set_entry_point("ingest")
    workflow.add_edge("ingest", "classify")
    workflow.add_edge("classify", "extract")
    workflow.add_edge("extract", "draft")
    workflow.add_edge("draft", END)
    
    # Compile
    return workflow.compile()


# Singleton agent instance
_agent = None

def get_agent():
    """Get or create the agent instance"""
    global _agent
    if _agent is None:
        _agent = create_inbox_agent()
    return _agent


async def process_message(
    message: str,
    message_type: str = None,
    sender_name: str = None,
    sender_contact: str = None,
    preferences: Optional[Dict[str, Any]] = None,
    conversation_history: Optional[str] = None,
) -> dict:
    """Process a message through the InboxCRM pipeline"""
    
    agent = get_agent()
    
    # Initial state
    initial_state: AgentState = {
        "raw_message": message,
        "message_type": message_type or "general",
        "intent": "",
        "urgency": "",
        "sentiment": "",
        "sender_name": sender_name,
        "sender_contact": sender_contact,
        "key_points": [],
        "action_items": [],
        "extracted_entities": {},
        "summary": "",
        "draft_response": "",
        "suggested_actions": [],
        "error": None,
        "processing_step": "",
        "preferences": preferences,
        "conversation_history": conversation_history,
    }
    
    try:
        # Run the agent
        final_state = await agent.ainvoke(initial_state)
        return {
            "success": True,
            "data": {
                "intent": final_state["intent"],
                "urgency": final_state["urgency"],
                "sentiment": final_state["sentiment"],
                "language": final_state.get("language"),
                "dialect": final_state.get("dialect"),
                "sender_name": final_state["sender_name"],
                "sender_contact": final_state["sender_contact"],
                "key_points": final_state["key_points"],
                "action_items": final_state["action_items"],
                "extracted_entities": final_state["extracted_entities"],
                "summary": final_state["summary"],
                "draft_response": final_state["draft_response"],
                "suggested_actions": final_state["suggested_actions"],
                "message_type": final_state["message_type"]
            }
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}"
        }

