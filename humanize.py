"""
Al-Mudeer Humanization Utilities
Anti-robotic patterns and natural language helpers
"""

from typing import List, Dict, Optional
import random
import re


# ============ Anti-Robotic Patterns ============

# Phrases to AVOID (robotic, overused, templated)
ROBOTIC_PHRASES = [
    # Overly formal greetings
    "Ø§Ù„Ø³ÙŠØ¯/Ø§Ù„Ø³ÙŠØ¯Ø© Ø§Ù„Ù…Ø­ØªØ±Ù…/Ø©",
    "Ù†ÙˆØ¯ Ø¥ÙØ§Ø¯ØªÙƒÙ…",
    "ÙŠØ³Ø±Ù†Ø§ Ø£Ù† Ù†Ø­ÙŠØ·ÙƒÙ… Ø¹Ù„Ù…Ø§Ù‹",
    "Ù†Ù‚Ø¯Ø± Ø«Ù‚ØªÙƒÙ… Ø§Ù„ØºØ§Ù„ÙŠØ© Ø¨Ù†Ø§",
    "Ù†Ø­Ù† Ø¨Ø®Ø¯Ù…ØªÙƒÙ… Ø¯Ø§Ø¦Ù…Ø§Ù‹ ÙˆØ£Ø¨Ø¯Ø§Ù‹",
    "ÙŠØ³Ø¹Ø¯Ù†Ø§ ÙˆÙŠØ´Ø±ÙÙ†Ø§ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ÙƒÙ…",
    
    # Repetitive closings
    "Ù…Ø¹ Ø£Ø·ÙŠØ¨ Ø§Ù„ØªØ­ÙŠØ§Øª ÙˆØ§Ù„ØªÙ‚Ø¯ÙŠØ± ÙˆØ§Ù„Ø§Ø­ØªØ±Ø§Ù…",
    "ÙˆÙ†Ø­Ù† ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± Ø±Ø¯ÙƒÙ… Ø§Ù„ÙƒØ±ÙŠÙ…",
    "Ù„Ø§ ØªØªØ±Ø¯Ø¯ÙˆØ§ ÙÙŠ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹Ù†Ø§ ÙÙŠ Ø£ÙŠ ÙˆÙ‚Øª",
    
    # Corporate jargon
    "ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø©",
    "Ù†Ù„ØªØ²Ù… Ø¨ØªÙ‚Ø¯ÙŠÙ… Ø£ÙØ¶Ù„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª",
    "Ù†Ø³Ø¹Ù‰ Ø¬Ø§Ù‡Ø¯ÙŠÙ† Ù„ØªØ­Ù‚ÙŠÙ‚ Ø±Ø¶Ø§ÙƒÙ…",
    "Ù†Ø­Ø±Øµ Ø¹Ù„Ù‰ ØªÙ„Ø¨ÙŠØ© ÙƒØ§ÙØ© Ø§Ø­ØªÙŠØ§Ø¬Ø§ØªÙƒÙ…",
    
    # Filler words
    "ÙˆØ¨Ø§Ù„ØªØ§Ù„ÙŠ",
    "ÙˆØ¹Ù„ÙŠÙ‡",
    "ÙˆÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø³ÙŠØ§Ù‚",
]


# Phrases to USE (natural, human-like)
NATURAL_PHRASES = {
    "acknowledgment": [
        "ÙÙ‡Ù…Øª Ø·Ù„Ø¨Ùƒ",
        "ÙˆØ§Ø¶Ø­",
        "ØªÙ…Ø§Ù…ØŒ Ø´ÙØª Ø±Ø³Ø§Ù„ØªÙƒ",
        "ÙˆØµÙ„ØªÙ†ÙŠ Ø±Ø³Ø§Ù„ØªÙƒ",
    ],
    "apology": [
        "Ø¢Ø³Ù Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø²Ø¹Ø§Ø¬",
        "Ù…Ø¹Ùƒ Ø­Ù‚",
        "Ø£ÙÙ‡Ù… Ø¥Ø­Ø¨Ø§Ø·Ùƒ",
        "Ù…Ø§ ÙƒØ§Ù† Ù„Ø§Ø²Ù… ÙŠØµÙŠØ± ÙƒØ°Ø§",
    ],
    "confirmation": [
        "Ø£ÙƒÙŠØ¯",
        "Ø·Ø¨Ø¹Ø§Ù‹",
        "Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡",
        "Ø­Ø§Ø¶Ø±",
    ],
    "closing": [
        "Ù…ÙˆØ¬ÙˆØ¯ÙŠÙ† Ù„Ø£ÙŠ Ø³Ø¤Ø§Ù„",
        "ØªÙˆØ§ØµÙ„ Ù…Ø¹Ù†Ø§ Ù…ØªÙ‰ Ù…Ø§ Ø§Ø­ØªØ¬Øª",
        "Ø¨Ø§Ù„Ø®Ø¯Ù…Ø©",
        "Ø£ÙŠ Ø´ÙŠ Ø«Ø§Ù†ÙŠØŸ",
    ],
    "transition": [
        "Ø¨Ø®ØµÙˆØµ",
        "Ø¹Ù† Ø³Ø¤Ø§Ù„Ùƒ",
        "Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù€",
        "Ø£Ù…Ø§ Ø¹Ù†",
    ],
}


# ============ Few-Shot Examples ============

# Real examples of good human-like responses for each intent
FEW_SHOT_EXAMPLES = {
    "Ø§Ø³ØªÙØ³Ø§Ø±": [
        {
            "customer": "ÙƒÙ… Ø³Ø¹Ø± Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø´Ù‡Ø±ÙŠØ©ØŸ",
            "response": """Ø£Ù‡Ù„Ø§Ù‹!

Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø´Ù‡Ø±ÙŠØ© Ø¨Ù€ 150 Ø¯ÙˆÙ„Ø§Ø±ØŒ ÙˆØªØ´Ù…Ù„ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª.

Ø¥Ø°Ø§ Ø­Ø§Ø¨ ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø± Ø£Ùˆ Ø¹Ù†Ø¯Ùƒ Ø£Ø³Ø¦Ù„Ø© Ø«Ø§Ù†ÙŠØ©ØŒ Ø£Ù†Ø§ Ù…ÙˆØ¬ÙˆØ¯ ğŸ‘‹"""
        },
        {
            "customer": "Ù‡Ù„ ØªÙ‚Ø¯Ù…ÙˆÙ† Ø®Ø¯Ù…Ø§Øª Ø§Ù„ØªÙˆØµÙŠÙ„ Ù„Ø¯Ù…Ø´Ù‚ØŸ",
            "response": """Ù…Ø±Ø­Ø¨Ø§Ù‹ØŒ

Ù†Ø¹Ù… Ù†ÙˆØµÙ„ Ù„Ø¯Ù…Ø´Ù‚ ÙˆØ±ÙŠÙÙ‡Ø§. Ø§Ù„ØªÙˆØµÙŠÙ„ ÙŠØ£Ø®Ø° Ø¹Ø§Ø¯Ø© 2-3 Ø£ÙŠØ§Ù… Ø¹Ù…Ù„.

Ø±Ø³ÙˆÙ… Ø§Ù„ØªÙˆØµÙŠÙ„ 5000 Ù„.Ø³ Ù„Ù„Ø·Ù„Ø¨Ø§Øª Ø£Ù‚Ù„ Ù…Ù† 50,000 Ù„.Ø³ØŒ ÙˆÙ…Ø¬Ø§Ù†Ø§Ù‹ Ù„Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø£ÙƒØ¨Ø±.

Ù‡Ù„ ØªØ­Ø¨ ØªÙƒÙ…Ù„ Ø§Ù„Ø·Ù„Ø¨ØŸ"""
        },
    ],
    
    "Ø´ÙƒÙˆÙ‰": [
        {
            "customer": "Ø§Ù„Ø·Ù„Ø¨ ØªØ£Ø®Ø± Ø£Ø³Ø¨ÙˆØ¹ ÙˆÙ„Ù… ÙŠØµÙ„ Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†!",
            "response": """Ø£Ù‡Ù„Ø§Ù‹ØŒ

Ø£ÙÙ‡Ù… ØªÙ…Ø§Ù…Ø§Ù‹ Ø¥Ø­Ø¨Ø§Ø·ÙƒØŒ Ø£Ø³Ø¨ÙˆØ¹ ÙØ¹Ù„Ø§Ù‹ ÙˆÙ‚Øª Ø·ÙˆÙŠÙ„ ÙˆÙ…Ùˆ Ù…Ù‚Ø¨ÙˆÙ„.

Ø®Ù„ÙŠÙ†ÙŠ Ø£ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ø¢Ù† ÙˆØ£Ø±Ø¬Ø¹Ù„Ùƒ Ø¨ØªØ­Ø¯ÙŠØ«. Ù„Ùˆ ÙÙŠ Ù…Ø´ÙƒÙ„Ø©ØŒ Ø±Ø§Ø­ Ù†Ù„Ø§Ù‚ÙŠ Ø­Ù„ Ù…Ù†Ø§Ø³Ø¨ Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡.

Ù…Ù…ÙƒÙ† ØªØ¹Ø·ÙŠÙ†ÙŠ Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨ØŸ"""
        },
        {
            "customer": "Ø§Ù„Ù…Ù†ØªØ¬ ÙˆØµÙ„ Ù…ÙƒØ³ÙˆØ±!",
            "response": """Ø£Ù‡Ù„Ø§Ù‹ØŒ

Ø¢Ø³Ù Ø¬Ø¯Ø§Ù‹ Ø¹Ù„Ù‰ Ù‡Ø§Ù„Ù…ÙˆÙ‚ÙØŒ Ù…Ø§ ÙƒØ§Ù† Ù„Ø§Ø²Ù… ÙŠØµÙŠØ± ÙƒØ°Ø§.

Ø§Ù„Ø­Ù„: Ø±Ø§Ø­ Ù†Ø±Ø³Ù„Ùƒ Ù…Ù†ØªØ¬ Ø¬Ø¯ÙŠØ¯ Ø§Ù„ÙŠÙˆÙ… Ø¨Ø¯ÙˆÙ† Ø£ÙŠ ØªÙƒÙ„ÙØ© Ø¥Ø¶Ø§ÙÙŠØ©. Ø¨Ø³ Ø£Ø±Ø³Ù„ÙŠ ØµÙˆØ±Ø© Ù„Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ù…ÙƒØ³ÙˆØ± Ù„Ù„ØªÙˆØ«ÙŠÙ‚.

Ù…Ø¹Ùƒ Ø­Ù‚ ØªÙƒÙˆÙ† Ø²Ø¹Ù„Ø§Ù†ØŒ ÙˆÙ†Ø­Ù† Ù†ØªØ­Ù…Ù„ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ©."""
        },
    ],
    
    "Ø·Ù„Ø¨ Ø®Ø¯Ù…Ø©": [
        {
            "customer": "Ø£Ø±ÙŠØ¯ Ø­Ø¬Ø² Ù…ÙˆØ¹Ø¯ ÙŠÙˆÙ… Ø§Ù„Ø£Ø­Ø¯",
            "response": """Ø£Ù‡Ù„Ø§Ù‹!

ØªÙ…Ø§Ù…ØŒ Ø§Ù„Ø£Ø­Ø¯ Ù…ØªØ§Ø­. Ø¹Ù†Ø¯Ù†Ø§ Ø£ÙˆÙ‚Ø§Øª:
- 10 Ø§Ù„ØµØ¨Ø­
- 2 Ø§Ù„Ø¸Ù‡Ø±  
- 5 Ø§Ù„Ø¹ØµØ±

Ø£ÙŠ ÙˆÙ‚Øª ÙŠÙ†Ø§Ø³Ø¨ÙƒØŸ"""
        },
    ],
    
    "Ù…ØªØ§Ø¨Ø¹Ø©": [
        {
            "customer": "Ø´Ùˆ ØµØ§Ø± Ø¨Ø·Ù„Ø¨ÙŠØŸ",
            "response": """Ø£Ù‡Ù„Ø§Ù‹ØŒ

Ø·Ù„Ø¨Ùƒ Ø§Ù„Ø¢Ù† Ø¹Ù†Ø¯ Ù‚Ø³Ù… Ø§Ù„Ø´Ø­Ù† ÙˆØ±Ø§Ø­ ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„Ù‡ Ø§Ù„ÙŠÙˆÙ… Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡.

Ø±Ø§Ø­ ØªÙˆØµÙ„Ùƒ Ø±Ø³Ø§Ù„Ø© ÙÙŠÙ‡Ø§ Ø±Ù‚Ù… Ø§Ù„ØªØªØ¨Ø¹ Ø¨Ù…Ø¬Ø±Ø¯ Ù…Ø§ ÙŠØªØ­Ø±Ùƒ."""
        },
    ],
}


# ============ Response Enhancement Functions ============

def remove_robotic_phrases(text: str) -> str:
    """Remove common robotic phrases from response"""
    result = text
    for phrase in ROBOTIC_PHRASES:
        result = result.replace(phrase, "")
    
    # Clean up extra whitespace
    result = re.sub(r'\n{3,}', '\n\n', result)
    result = re.sub(r' {2,}', ' ', result)
    
    return result.strip()


def add_natural_element(response: str, element_type: str) -> str:
    """Add a natural phrase of specified type"""
    if element_type in NATURAL_PHRASES:
        phrase = random.choice(NATURAL_PHRASES[element_type])
        return phrase
    return ""


def get_few_shot_example(intent: str) -> Optional[Dict]:
    """Get a random few-shot example for the given intent"""
    examples = FEW_SHOT_EXAMPLES.get(intent, [])
    if examples:
        return random.choice(examples)
    return None


def build_few_shot_prompt(intent: str) -> str:
    """Build few-shot prompt section for the given intent"""
    example = get_few_shot_example(intent)
    if not example:
        return ""
    
    return f"""
Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø±Ø¯ Ø¬ÙŠØ¯:
Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„: {example['customer']}
Ø§Ù„Ø±Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
{example['response']}

---
"""


# ============ Response Quality Checks ============

def check_response_quality(response: str) -> Dict[str, any]:
    """Check response quality and return issues"""
    issues = []
    suggestions = []
    score = 100
    
    # Check for robotic phrases
    for phrase in ROBOTIC_PHRASES[:10]:
        if phrase in response:
            issues.append(f"ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ø¨Ø§Ø±Ø© Ù†Ù…Ø·ÙŠØ©: {phrase}")
            score -= 10
    
    # Check length
    if len(response) > 800:
        issues.append("Ø§Ù„Ø±Ø¯ Ø·ÙˆÙŠÙ„ Ø¬Ø¯Ø§Ù‹")
        suggestions.append("Ø§Ø®ØªØµØ± Ø§Ù„Ø±Ø¯ Ù„ÙŠÙƒÙˆÙ† Ø£Ù‚Ù„ Ù…Ù† 800 Ø­Ø±Ù")
        score -= 15
    elif len(response) < 50:
        issues.append("Ø§Ù„Ø±Ø¯ Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹")
        suggestions.append("Ø£Ø¶Ù ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø±")
        score -= 10
    
    # Check for missing greeting
    greetings = ["Ø£Ù‡Ù„Ø§Ù‹", "Ù…Ø±Ø­Ø¨Ø§Ù‹", "Ù‡Ù„Ø§", "Ø§Ù„Ø³Ù„Ø§Ù…"]
    has_greeting = any(g in response[:50] for g in greetings)
    if not has_greeting:
        suggestions.append("Ø£Ø¶Ù ØªØ­ÙŠØ© ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©")
        score -= 5
    
    # Check for all caps (shouting)
    if response.isupper():
        issues.append("Ø§Ù„Ø±Ø¯ Ø¨Ø­Ø±ÙˆÙ ÙƒØ¨ÙŠØ±Ø© (ÙŠØ¨Ø¯Ùˆ ÙƒØµØ±Ø§Ø®)")
        score -= 20
    
    return {
        "score": max(0, score),
        "issues": issues,
        "suggestions": suggestions,
        "is_good": score >= 70,
    }


# ============ Dynamic Temperature ============

def get_dynamic_temperature(intent: str, sentiment: str, persona_base: float = 0.3) -> float:
    """Calculate dynamic temperature based on context"""
    temp = persona_base
    
    # Complaints need careful, consistent responses
    if intent == "Ø´ÙƒÙˆÙ‰":
        temp = max(0.2, temp - 0.1)
    
    # Negative sentiment needs more careful responses
    if sentiment == "Ø³Ù„Ø¨ÙŠ":
        temp = max(0.2, temp - 0.1)
    
    # Sales inquiries can be more creative
    if intent == "Ø¹Ø±Ø¶":
        temp = min(0.6, temp + 0.15)
    
    # General inquiries can have some variation
    if intent == "Ø§Ø³ØªÙØ³Ø§Ø±":
        temp = min(0.5, temp + 0.1)
    
    return round(temp, 2)


# ============ Anti-Repetition ============

# Track recent phrases to avoid repetition
_recent_phrases = []
MAX_RECENT = 10


def avoid_repetition(phrase: str) -> bool:
    """Check if phrase was used recently, track it if not"""
    global _recent_phrases
    
    # Normalize phrase
    normalized = phrase.strip().lower()[:50]
    
    if normalized in _recent_phrases:
        return False  # Skip this phrase
    
    # Add to recent and trim
    _recent_phrases.append(normalized)
    if len(_recent_phrases) > MAX_RECENT:
        _recent_phrases.pop(0)
    
    return True


def get_unique_greeting(persona_name: str, customer_name: str = None) -> str:
    """Get a greeting that wasn't used recently"""
    from personas import GREETINGS
    
    greetings = GREETINGS.get(persona_name, GREETINGS.get("formal", []))
    random.shuffle(greetings)
    
    for greeting in greetings:
        if "{name}" in greeting:
            name = customer_name or "Ø¹Ø²ÙŠØ²ÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ„"
            greeting = greeting.replace("{name}", name)
        
        if avoid_repetition(greeting):
            return greeting
    
    # Fallback if all used recently
    return greetings[0] if greetings else "Ù…Ø±Ø­Ø¨Ø§Ù‹ØŒ"
